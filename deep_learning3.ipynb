{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Red Neuronal Recurrente"
      ],
      "metadata": {
        "id": "YxP2wy5ljxcg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruqSVc-wB-HP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLa2-PSLGasg"
      },
      "source": [
        "\n",
        "**Libro:** Orgullo y Prejuicio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiZraOnbFo9t",
        "outputId": "12a6dbee-af7c-4afe-9c7c-c6acc3023ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitud del texto: 690571 caracteres\n",
            "El texto está compuesto de estos 96 caracteres\n",
            "['\\t', '\\n', '\\r', ' ', '!', '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x96', '\\x97', '¡', '«', '»', '¿', 'É', 'Í', 'Ú', 'à', 'á', 'é', 'ê', 'í', 'ñ', 'ó', 'ú', 'ü']\n"
          ]
        }
      ],
      "source": [
        "local_file_path = 'orgulloyprejuicio.txt'\n",
        "\n",
        "text = open(local_file_path, 'rb').read().decode(encoding='latin-1')\n",
        "print('Longitud del texto: {} caracteres'.format(len(text)))\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "print('El texto está compuesto de estos {} caracteres'.format(len(vocab)))\n",
        "print(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui1JDj2TGZPT"
      },
      "source": [
        "## Tablas de traducción o inversa de vocabulario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAJByCaMGYx6"
      },
      "outputs": [],
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egp7iCWSGi1T",
        "outputId": "ca1dce7c-7780-409c-d071-f50382b68d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " '\\t':   0,\n",
            " '\\n':   1,\n",
            " '\\r':   2,\n",
            " ' ' :   3,\n",
            " '!' :   4,\n",
            " '(' :   5,\n",
            " ')' :   6,\n",
            " ',' :   7,\n",
            " '-' :   8,\n",
            " '.' :   9,\n",
            " '0' :  10,\n",
            " '1' :  11,\n",
            " '2' :  12,\n",
            " '3' :  13,\n",
            " '4' :  14,\n",
            " '5' :  15,\n",
            " '6' :  16,\n",
            " '7' :  17,\n",
            " '8' :  18,\n",
            " '9' :  19,\n",
            " ':' :  20,\n",
            " ';' :  21,\n",
            " '>' :  22,\n",
            " '?' :  23,\n",
            " 'A' :  24,\n",
            " 'B' :  25,\n",
            " 'C' :  26,\n",
            " 'D' :  27,\n",
            " 'E' :  28,\n",
            " 'F' :  29,\n",
            " 'G' :  30,\n",
            " 'H' :  31,\n",
            " 'I' :  32,\n",
            " 'J' :  33,\n",
            " 'K' :  34,\n",
            " 'L' :  35,\n",
            " 'M' :  36,\n",
            " 'N' :  37,\n",
            " 'O' :  38,\n",
            " 'P' :  39,\n",
            " 'Q' :  40,\n",
            " 'R' :  41,\n",
            " 'S' :  42,\n",
            " 'T' :  43,\n",
            " 'U' :  44,\n",
            " 'V' :  45,\n",
            " 'W' :  46,\n",
            " 'X' :  47,\n",
            " 'Y' :  48,\n",
            " 'Z' :  49,\n",
            " '[' :  50,\n",
            " ']' :  51,\n",
            " 'a' :  52,\n",
            " 'b' :  53,\n",
            " 'c' :  54,\n",
            " 'd' :  55,\n",
            " 'e' :  56,\n",
            " 'f' :  57,\n",
            " 'g' :  58,\n",
            " 'h' :  59,\n",
            " 'i' :  60,\n",
            " 'j' :  61,\n",
            " 'k' :  62,\n",
            " 'l' :  63,\n",
            " 'm' :  64,\n",
            " 'n' :  65,\n",
            " 'o' :  66,\n",
            " 'p' :  67,\n",
            " 'q' :  68,\n",
            " 'r' :  69,\n",
            " 's' :  70,\n",
            " 't' :  71,\n",
            " 'u' :  72,\n",
            " 'v' :  73,\n",
            " 'w' :  74,\n",
            " 'x' :  75,\n",
            " 'y' :  76,\n",
            " 'z' :  77,\n",
            " '\\x96':  78,\n",
            " '\\x97':  79,\n",
            " '¡' :  80,\n",
            " '«' :  81,\n",
            " '»' :  82,\n",
            " '¿' :  83,\n",
            " 'É' :  84,\n",
            " 'Í' :  85,\n",
            " 'Ú' :  86,\n",
            " 'à' :  87,\n",
            " 'á' :  88,\n",
            " 'é' :  89,\n",
            " 'ê' :  90,\n",
            " 'í' :  91,\n",
            " 'ñ' :  92,\n",
            " 'ó' :  93,\n",
            " 'ú' :  94,\n",
            " 'ü' :  95,\n"
          ]
        }
      ],
      "source": [
        "for char,_ in zip(char2idx, range(len(vocab))):\n",
        "  print(' {:4s}: {:3d},'.format(repr(char), char2idx[char]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inFIb0T2Gmj6"
      },
      "source": [
        "## Conversión de texto a enteros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L55eZBroGlCp"
      },
      "outputs": [],
      "source": [
        "text_as_int = np.array([char2idx[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD_RfOqoGqdo",
        "outputId": "d533b288-30d2-4e9a-e976-9aa8af749611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: ' LIBROdot.com\\r\\n  \\r\\n  Jane Austen\\r\\n  Orgullo y Prej'\n",
            "array([ 3, 35, 32, 25, 41, 38, 55, 66, 71,  9, 54, 66, 64,  2,  1,  3,  3,\n",
            "        2,  1,  3,  3, 33, 52, 65, 56,  3, 24, 72, 70, 71, 56, 65,  2,  1,\n",
            "        3,  3, 38, 69, 58, 72, 63, 63, 66,  3, 76,  3, 39, 69, 56, 61])\n"
          ]
        }
      ],
      "source": [
        "print('text: {}'.format(repr(text[:50])))\n",
        "print('{}'.format(repr(text_as_int[:50])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdxFNgIdGv4F"
      },
      "source": [
        "## Preparación de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WmegZI8Gxdh"
      },
      "outputs": [],
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "seq_length = 100\n",
        "\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5jGMumNHCw3",
        "outputId": "301cddd1-2a42-496b-9577-34dbaee98619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "' LIBROdot.com\\r\\n  \\r\\n  Jane Austen\\r\\n  Orgullo y Prejuicio\\r\\n     \\r\\n     \\r\\n\\r\\nCAPÍTULO I\\r\\n       Es una ve'\n",
            "'rdad mundialmente reconocida que un hombre soltero, poseedor de una gran fortuna, necesita una esposa'\n",
            "'.\\r\\n       Sin embargo, poco se sabe de los sentimientos u opiniones de un hombre de tales condiciones'\n",
            "' cuando entra a formar parte de un vecindario. Esta verdad está tan arraigada en las mentes de alguna'\n",
            "'s de las familias que lo rodean, que algunas le consideran de su legítima propiedad y otras de la de '\n",
            "'sus hijas.\\r\\n       \\x96\\x96Mi querido señor Bennet \\x96\\x96le dijo un día su esposa\\x96\\x96, ¿sabías que, por fin, se h'\n",
            "'a alquilado Netherfield Park?\\r\\n       El señor Bennet respondió que no.\\r\\n       \\x96\\x96Pues así es \\x96\\x96insis'\n",
            "'tió ella\\x96\\x96; la señora Long ha estado aquí hace un momento y me lo ha contado todo.\\r\\n       El señor B'\n",
            "'ennet no hizo ademán de contestar. \\r\\n       \\x96\\x96¿No quieres saber quién lo ha alquilado? \\x96\\x96se impacient'\n",
            "'ó su esposa.\\r\\n       \\x96\\x96Eres tú la que quieres contármelo, y yo no tengo inconveniente en oírlo.\\r\\n    '\n"
          ]
        }
      ],
      "source": [
        "for item in sequences.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYQqk10BHEra"
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMZj-R_6HIh4",
        "outputId": "5d80c4a2-364d-4d31-bcf3-8b62cc019a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:  ' LIBROdot.com\\r\\n  \\r\\n  Jane Austen\\r\\n  Orgullo y Prejuicio\\r\\n     \\r\\n     \\r\\n\\r\\nCAPÍTULO I\\r\\n       Es una v'\n",
            "Target data:  'LIBROdot.com\\r\\n  \\r\\n  Jane Austen\\r\\n  Orgullo y Prejuicio\\r\\n     \\r\\n     \\r\\n\\r\\nCAPÍTULO I\\r\\n       Es una ve'\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEiuxfwTHKtr",
        "outputId": "882393e1-4a97-4348-a7f0-1652359386c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "print (dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHPzoB00HMuc",
        "outputId": "88147be4-8aeb-43ef-b39e-e67a0d523c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9CrGyATHQe_"
      },
      "source": [
        "## Modelo RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNiYkxkhHP4p"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                batch_input_shape=[batch_size,None]),\n",
        "\n",
        "      tf.keras.layers.LSTM(rnn_units,\n",
        "                           return_sequences=True,\n",
        "                           stateful = True,\n",
        "                           recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "      tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim= 256\n",
        "rnn_units = 1024\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size = vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwQPKC-3HVre",
        "outputId": "a00c22df-8cf2-41a4-8402-91293569b16d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           24576     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 96)            98400     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5369952 (20.48 MB)\n",
            "Trainable params: 5369952 (20.48 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUsEoPGQIP5v",
        "outputId": "3be43cf9-61d0-4122-b349-af73c4ee6c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  (64, 100) # (batch_size, lenght)\n",
            "Target:  (64, 100) # (batch_size, sequence_length)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  print(\"Input: \", input_example_batch.shape, \"# (batch_size, lenght)\")\n",
        "  print(\"Target: \", target_example_batch.shape, \"# (batch_size, sequence_length)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s21txK_ZISjH",
        "outputId": "64b153cf-e8e1-4a4a-92ac-6399207a3aec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:  (64, 100, 96) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(\"Prediction: \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABM9mu04IU_s",
        "outputId": "41598b72-5964-4b03-e34e-340433b34094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[73 48 66 88 35  8 54 79 84 72 94 84 54 28 50 86 39 92 91 76 18 56 16 82\n",
            " 61 28 16 30  1 34 34 12 22 39 87 23 93 17 29 35 62  5 24 36 13 66 38 58\n",
            " 69 35 87 11 73 30 49 46 38 22 39 18 18 23 72 88 41 74 76 47 57 92 29 84\n",
            " 72 70  6 33 59 88 88 58 24 12 71 28 48 44 93 57 44 55  3 75 88  2 61 58\n",
            " 95 56 53 92]\n"
          ]
        }
      ],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices_characters = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "print(sampled_indices_characters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy0U_r77IYgS"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQMyPf4sIWMM"
      },
      "outputs": [],
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sALIs3G3IgPI"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_(epoch)\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_kh3gokIjGD",
        "outputId": "95165509-e579-4c6c-9216-26183ceaca38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "106/106 [==============================] - 12s 82ms/step - loss: 2.7653\n",
            "Epoch 2/50\n",
            "106/106 [==============================] - 9s 72ms/step - loss: 2.0305\n",
            "Epoch 3/50\n",
            "106/106 [==============================] - 8s 67ms/step - loss: 1.7281\n",
            "Epoch 4/50\n",
            "106/106 [==============================] - 9s 68ms/step - loss: 1.5147\n",
            "Epoch 5/50\n",
            "106/106 [==============================] - 8s 67ms/step - loss: 1.3745\n",
            "Epoch 6/50\n",
            "106/106 [==============================] - 8s 68ms/step - loss: 1.2851\n",
            "Epoch 7/50\n",
            "106/106 [==============================] - 9s 68ms/step - loss: 1.2214\n",
            "Epoch 8/50\n",
            "106/106 [==============================] - 8s 69ms/step - loss: 1.1741\n",
            "Epoch 9/50\n",
            "106/106 [==============================] - 8s 70ms/step - loss: 1.1361\n",
            "Epoch 10/50\n",
            "106/106 [==============================] - 9s 70ms/step - loss: 1.1009\n",
            "Epoch 11/50\n",
            "106/106 [==============================] - 9s 70ms/step - loss: 1.0703\n",
            "Epoch 12/50\n",
            "106/106 [==============================] - 10s 71ms/step - loss: 1.0409\n",
            "Epoch 13/50\n",
            "106/106 [==============================] - 9s 71ms/step - loss: 1.0113\n",
            "Epoch 14/50\n",
            "106/106 [==============================] - 9s 72ms/step - loss: 0.9832\n",
            "Epoch 15/50\n",
            "106/106 [==============================] - 9s 72ms/step - loss: 0.9546\n",
            "Epoch 16/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.9243\n",
            "Epoch 17/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.8920\n",
            "Epoch 18/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.8606\n",
            "Epoch 19/50\n",
            "106/106 [==============================] - 10s 73ms/step - loss: 0.8288\n",
            "Epoch 20/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.7948\n",
            "Epoch 21/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.7610\n",
            "Epoch 22/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.7264\n",
            "Epoch 23/50\n",
            "106/106 [==============================] - 9s 72ms/step - loss: 0.6913\n",
            "Epoch 24/50\n",
            "106/106 [==============================] - 9s 72ms/step - loss: 0.6577\n",
            "Epoch 25/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.6269\n",
            "Epoch 26/50\n",
            "106/106 [==============================] - 9s 74ms/step - loss: 0.5950\n",
            "Epoch 27/50\n",
            "106/106 [==============================] - 9s 74ms/step - loss: 0.5655\n",
            "Epoch 28/50\n",
            "106/106 [==============================] - 9s 72ms/step - loss: 0.5378\n",
            "Epoch 29/50\n",
            "106/106 [==============================] - 9s 74ms/step - loss: 0.5114\n",
            "Epoch 30/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.4888\n",
            "Epoch 31/50\n",
            "106/106 [==============================] - 9s 74ms/step - loss: 0.4699\n",
            "Epoch 32/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.4486\n",
            "Epoch 33/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.4301\n",
            "Epoch 34/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.4143\n",
            "Epoch 35/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.4007\n",
            "Epoch 36/50\n",
            "106/106 [==============================] - 10s 73ms/step - loss: 0.3880\n",
            "Epoch 37/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.3751\n",
            "Epoch 38/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.3653\n",
            "Epoch 39/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.3566\n",
            "Epoch 40/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.3485\n",
            "Epoch 41/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.3407\n",
            "Epoch 42/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.3349\n",
            "Epoch 43/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.3281\n",
            "Epoch 44/50\n",
            "106/106 [==============================] - 10s 73ms/step - loss: 0.3209\n",
            "Epoch 45/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.3176\n",
            "Epoch 46/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.3142\n",
            "Epoch 47/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.3099\n",
            "Epoch 48/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.3057\n",
            "Epoch 49/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.3014\n",
            "Epoch 50/50\n",
            "106/106 [==============================] - 9s 73ms/step - loss: 0.2998\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación de texto"
      ],
      "metadata": {
        "id": "vTj4HVKYiGWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "metadata": {
        "id": "goCJcT4kiEHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_strings, temperatures):\n",
        "    num_generate = 500\n",
        "\n",
        "    generated_texts = []\n",
        "\n",
        "    for start_string in start_strings:\n",
        "        for temperature in temperatures:\n",
        "            input_eval = [char2idx[s] for s in start_string]\n",
        "            input_eval = tf.expand_dims(input_eval, 0)\n",
        "            text_generated = []\n",
        "\n",
        "            model.reset_states()\n",
        "            for _ in range(num_generate):\n",
        "                predictions = model(input_eval)\n",
        "                predictions = tf.squeeze(predictions, 0)\n",
        "                predictions = predictions / temperature\n",
        "                predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "                input_eval = tf.expand_dims([predicted_id], 0)\n",
        "                text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "            generated_texts.append(start_string + ''.join(text_generated))\n",
        "\n",
        "    return generated_texts"
      ],
      "metadata": {
        "id": "4xlsDEBwiGC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_strings = [\"amor\", \"misterio\"]\n",
        "temperatures = [0.5, 1.0, 1.5]"
      ],
      "metadata": {
        "id": "yBqlq2kGiXlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_texts = generate_text(model, start_strings, temperatures)"
      ],
      "metadata": {
        "id": "0aWE_4J6idxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, text in enumerate(generated_texts):\n",
        "    print(f\"Entrada: {start_strings[i // 3]}, Temperatura: {temperatures[i % 3]}\")\n",
        "    print(text)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgPD9oYhif21",
        "outputId": "01cf953f-a940-4ad9-8bd6-066effd805aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrada: amor, Temperatura: 0.5\n",
            "amorarse de él está la de salir de la solicia de la casa del párroco. El señor Denny se dirigió directamente a la escacia que el hablar de su hermana y se quedó muy satisfecha y proporcionaban la finca en la que está ubicada mi hermana antes de que la familia se acostase.\r\n",
            "       La señorita Bingley le preguntó si están en Londad se alegraba. Sólo podía pensar en la misma profesión, aunque de distruir un poderoso respeto que el señor Bingley le devolvió la visita al señor Bennet y no dudo de que pro\n",
            "\n",
            "Entrada: amor, Temperatura: 1.0\n",
            "amorarse al principio la señora Bennet, a Elizabeth y a una particular a mi hermana clara usted más de la iglesia de buscarles o casi ver que el coronel Forster y el deseo de la tarde de la habitación y la acompañó hasta esta última de las sospechas, los dos tan excedentes no se les vio obligada a pensar que el ruido de un caballero y amigos de la falta de fortuna a la hora de comprometerse, ¿qué va a sañad?\r\n",
            "       Nunca benir a Elizabeth tuy le apetecible y amigos de las carreteras más vacilas d\n",
            "\n",
            "Entrada: amor, Temperatura: 1.5\n",
            "amora si yo estuve de BSingl y go la de que Jane los habrían quincepado, y sólo querría iba la preñadiles; para ella desde ha felicidad nada tan bonito con Darcy. Se ha costed de Joner, pero al cabo de haber limporta buena parte del campo.\r\n",
            "       No es nada en comparación con el anhástamel nada opuesta de labinicias, «lintras de Pemo pueden nco que esperomo, querida. Le recomendó que se sentñacie.\r\n",
            "    mente orgulloso, por consiguiente, cruzaba la elegida en sus gusando tiernos sentimientos, de j\n",
            "\n",
            "Entrada: misterio, Temperatura: 0.5\n",
            "misterio, Elizabeth prefirió no darse cuenta de que no eran necesarias por la historia de su mujer. Pero si en esa circunstancia, yo me estabas todo detando el consajer que su madre pronto le dio a entender que la posibilidad de aquel matrimonio la pausa de un minuto, empezó otra canción. Al pasar por el vestíbulo, lady Catherine abrió las puertas de la familia de Longbourn no tenía ninguno como si la otra vez, de ella que era la medida más intencionada que no hay por qué ponerle en tan mal lugar. ¿Tú q\n",
            "\n",
            "Entrada: misterio, Temperatura: 1.0\n",
            "misteriorarle una espantosa palabra de su amor; si no lo hiz. Los ojos de la señorita Bingley con gran sera Forster la partida de chimo, dijo que se había aparentar la mayor ni la mitad de las cosas que tenía que comunicarle a su marido.\r\n",
            "       Después de la decepción que sentía lo que decían y se ufanó de las frases y observaba a aficio a otro de la señora Jenkinson. Se expresasó su aprimó a la boda le situalizabeth, desde que se alegraría mucho de veros a todos antes de doy mi  Elizabeth no contestó.\n",
            "\n",
            "Entrada: misterio, Temperatura: 1.5\n",
            "misterio.\r\n",
            "       ¿No seré usted porque él mismo dia creciente por quencia. Siempre Senté fijabeth recordó la bondad.» ía una de que venías, no aparecieron que no se le querdaría mucho que Darcy algunas de una mañana en su treo, embargó ese más e enoín, demás.\r\n",
            "  [L19]...y cuanto Darcy se levantó y después de mostrarxill        Elizabeth pareció haber hecho un esperando se vieron libres. Fina corres menos fuerza. \r\n",
            "    po, y el mismo de Elizabeth yas le impía mejor encantadora. Un llegada a Charlotte \n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}